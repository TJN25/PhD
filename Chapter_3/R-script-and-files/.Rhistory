filter(!is.na(distance.breaks.short))%>%
select(distance.breaks.short, target.density.values, non.target.density.values, random.mean.t.density.values, random.mean.n.density.values)
max <- max(c(max(dat$target.density.values), max(dat$non.target.density.values)))
dat <- dat%>%
mutate(target.density.values = target.density.values/max)%>%
mutate(non.target.density.values = -non.target.density.values/max)%>%
mutate(random.mean.t.density.values = random.mean.t.density.values/max)%>%
mutate(random.mean.n.density.values = -random.mean.n.density.values/max)
tmp <- dat%>%select(non.target.density.values)%>%mutate(line.number = c(nrow(dat):1))
dat <- dat%>%select(-non.target.density.values)%>%mutate(line.number = c(1:nrow(dat)))
dat <- left_join(dat, tmp, by = "line.number")
dat <- dat%>%select(distance.breaks.short, target.density.values, non.target.density.values, random.mean.t.density.values, random.mean.n.density.values)
row.null.neg <- c(-10000, 0,0,0,0)
row.null.pos <- c(10000, 0,0,0,0)
dat <- rbind(row.null.neg, dat, row.null.pos)
return(dat)
}
##gives a p-value and clustering % for a subtype
cluster_analysis <- function(swipeData = swipeData, Subtype.label = "I-F"){
subtypeData = swipeData%>%filter(Subtype == Subtype.label)
loop.length = 1000
set.seed(100)
targets.dat.replicated <- subtypeData[rep(seq_len(nrow(subtypeData)), loop.length), ]
#targets.dat.replicated%>%targets.dat.replicated%>%filter(spacer.order_num > 1)
rh <- targets.dat.replicated%>%
mutate(distance.to.protospacer = runif(min = -0.5, max = 0.5, n = nrow(targets.dat.replicated)))%>%
mutate(distance.to.protospacer = round(distance.to.protospacer*genome.length, 0))%>%
mutate(distance.to.protospacer = ifelse(spacer.order.number == 1, 0, distance.to.protospacer))%>%
mutate(target.strand = round(runif(min = 0, max = 1, n = nrow(targets.dat.replicated)), 0))%>%
mutate(target.strand = ifelse(target.strand == 1, "t", "n"))%>%
mutate(five.three.prime.dir = ifelse(distance.to.protospacer < 0, ifelse(target.strand == "t", 5, 3), ifelse(target.strand == "t", 3, 5)))%>%
mutate(strand.plus.direction = paste(target.strand, five.three.prime.dir, sep = "_"))%>%
mutate(target.pos = runif(min = 0, max = 1, n = nrow(targets.dat.replicated)))%>%
mutate(target.pos = round(target.pos*genome.length, 0))
rm(targets.dat.replicated)
rh <- rh%>%group_by(host.target.pair, array.id, spacer.id, spacer.order.number)%>%mutate(replicate = row_number())%>%filter(spacer.order.number > 1)
dat <- subtypeData%>%filter(spacer.order.number > 1)
mean.distance<- rh%>%group_by(replicate)%>%summarise(mean.value = mean(abs(distance.to.protospacer)))
sd.distance<- rh%>%group_by(replicate)%>%summarise(sd.value = sd(distance.to.protospacer))
distanceSummaryRH <- left_join(mean.distance, sd.distance, by = "replicate")
mean.mean <- mean(distanceSummaryRH$mean.value)
sd.mean <- sd(distanceSummaryRH$mean.value)
mean.sd <- mean(distanceSummaryRH$sd.value)
sd.sd <- sd(distanceSummaryRH$sd.value)
n = length(dat$distance.to.protospacer)
s = sd(dat$distance.to.protospacer)        # sample standard deviation
SE = s/sqrt(n)
E = qt(.975, df=n-1)*SE
xbar = mean(abs(dat$distance.to.protospacer))   # sample mean
ciData <- xbar + c(-E, E)
n = length(rh$distance.to.protospacer)
s = sd(rh$distance.to.protospacer)        # sample standard deviation
SE = s/sqrt(n)
E = qt(.975, df=n-1)*SE
xbar = mean(abs(rh$distance.to.protospacer))   # sample mean
ciRandom <- xbar + c(-E, E)
return(paste(Subtype.label, pnorm(ciData[2], mean=mean.sd, sd=sd.sd, lower.tail=T), (mean(abs(rh$distance.to.protospacer)) - mean(abs(dat$distance.to.protospacer)))/mean(abs(rh$distance.to.protospacer))*100 ))
}
##gives a p-value for the ks-test results
ks_test_analysis <- function(swipeData, rh, Subtype.label = "I-F"){
sr <- rh%>%filter(Subtype == Subtype.label)%>%filter(spacer.order.number > 1)
##label the data as random and include the group number
sr <- sr%>%mutate(data.type = paste("random", group.number, sep = "_"))%>%
mutate(data.type = ifelse(data.type == "random_1", "random_01", data.type))
##select the data that will be needed for determining posisiton
sr <- sr%>%select(distance.to.protospacer, data.type, strand.plus.direction)
st <- swipeData%>%filter(Subtype == Subtype.label)%>%filter(spacer.order.number > 1)
##label the data as target
st <- st%>%mutate(data.type = "targets")%>%
mutate(strand = ifelse(strand.plus.direction == "n_5", "n", ifelse(strand.plus.direction == "n_3", "n", "t")))%>%
select(-strand)
##select the data that will be needed for determining posisiton
st <- st%>%select(distance.to.protospacer, data.type, strand.plus.direction)
ks.res <- suppressWarnings(ks.test(sr$distance.to.protospacer, st$distance.to.protospacer))
return(ks.res)
}
swipeData <-  read.table("refseq_83_swipe_PPS.scores.txt", comment.char = "", fill = T, sep = "\t", header = T)
knitr::opts_chunk$set(echo = TRUE)
#install.packages("EMT")
##load packages
library(EMT)
library(tidyverse)
library(zoo)
#install.packages("EMT")
##load packages
library(EMT)
install.packages("zoo")
library(zoo)
install.packages("EMT")
library(EMT)
setwd("~/Dropbox/Fineran-Brown/R-script-and-files")
Out.Dir<-"Output/"
quadrant_analysis<-function(dat, Subtype.label, use.all.hits){
dat<-dat%>%filter(Subtype == Subtype.label) # move this out of the function to allow type II systems to be pooled?
if(use.all.hits == T){
Data<-dat%>%filter(spacer.order.number >= 2)
}else if(use.all.hits == F){
Data<-dat%>%filter(spacer.order.number == 2 | spacer.order.number == 3)
#@@ testing         Data<-dat%>%filter(spacer.order.number == 2)
}
Data<-Data%>%mutate(tmp = paste(target.strand, five.three.prime.dir, sep = "_"))
quadrants<-as.data.frame(table(Data$tmp))
total<-sum(quadrants$Freq)
quadrants<-quadrants%>%mutate(percentage = round(Freq/total*100, 2))
strands<-as.data.frame(table(Data$target.strand))
strands<-strands%>%mutate(percentage = round(Freq/total*100, 2))
mat<-matrix(c(round(quadrants[4,2]), round(quadrants[3,2]),round(quadrants[1,2]), round(quadrants[2,2]) ), nrow = 2, byrow = T) #@@ Does this do anything?
quadrants<-quadrants%>%mutate(rowNum = c(3,4,1,2))%>%arrange(rowNum)%>%select(-rowNum)
#mat.res<-multinomial.test(observed = quadrants$Freq, prob = c(0.25, 0.25, 0.25, 0.25), MonteCarlo = T, ntrial = 10000000) @@ I don't think the Monte Carlo is necessary for our (simple) system - you need to run lots of trials for this to give a valid p value. On my laptop it is faster to run the mathematical version....
strands.prob<-binom.test(strands$Freq[2],total,p=0.5)
mat.res<-multinomial.test(observed = quadrants$Freq, prob = c(0.25, 0.25, 0.25, 0.25))
#Out.Table<-tbl_df("Host-Target pairs")%>%mutate(Freq=length(unique(Data$host.target.pair)))
Host.Target.Pairs<-nrow(Data%>%filter(spacer.order.number==1))
Out.Table<-tbl_df("Host-Target pairs")%>%mutate(Freq=Host.Target.Pairs)
Out.Table<-Out.Table%>%bind_rows(tbl_df("Hits not incl. PPS")%>%mutate(Freq=total))
Out.Table<-Out.Table%>%bind_rows(tbl_df("Quadrant p-value")%>%mutate(Freq=round(mat.res$p.value, 4)))
Out.Table<-Out.Table%>%bind_rows(tbl_df("Strand p-value")%>%mutate(Freq=round(strands.prob$p.value,4)))
Out.Table<-Out.Table%>%rename("Var1"=value)
Out.Table<-Out.Table%>%full_join(quadrants)%>%full_join(strands)
Out.Table[is.na(Out.Table)]<-0
print(paste("Subtype =",Subtype.label))
print(Out.Table)
#print(strands)
#print(quadrants)
return(Out.Table)
} ##Looks at the strand and quadrant distributions. It only needs swipeData and a subtype to run.
generate_random_distributionB<-function(swipeData,Size){ # Uses the same distance and strand calling as the main script including circular genome correction.
##generate the random dataset
set.seed(100)
# Trim the table
swipeData<-swipeData%>%select(host.target.pair,Subtype,array.id,target.acc.,unique.spacer.target.match,spacer.order.number,target.pos,strand,genome.length)
# Generate dataset with n (Size) replicates
targets.dat.replicated<-swipeData[rep(seq_len(nrow(swipeData)), Size), ]
targets.dat.replicated<-targets.dat.replicated%>%arrange(unique.spacer.target.match)%>%mutate(trial = rep(1:Size, nrow(swipeData)))%>%
mutate(host.target.pair=paste(host.target.pair,"_rep",trial,sep=""))
#length(targets.dat.replicated)-length(unique(targets.dat.replicated))
# Randomly assign protospacer sites and strands
Rnd.Data<-targets.dat.replicated%>%rowwise()%>%mutate(strand=sample(c(-1,1),1))%>%mutate(target.pos=sample(genome.length,1))
# Now perform the same strand and distance assignments as the main script
# Get the PPS data so that columns containing position and strand can be used to work out strand and direction for the subsequent matches
ppsData<-Rnd.Data%>%filter(spacer.order.number == 1)%>%
mutate(pps.strand = strand)%>%
mutate(pps.target.pos = target.pos)%>%
select(host.target.pair, pps.strand, pps.target.pos)
Data<-Rnd.Data%>%left_join(ppsData, by = "host.target.pair")%>%ungroup()
# Set the PPS to always be the top strand - if the PPS is on the bottom strand, reverse complement the target and change the position values
To.Rev.Comp<-Data%>%filter(pps.strand==-1)
# Flip the strand
To.Rev.Comp<-To.Rev.Comp%>%mutate(strand=strand*-1,pps.strand=pps.strand*-1,target.pos=(genome.length-target.pos),pps.target.pos=(genome.length-pps.target.pos))
# Rejoin the data
Data<-Data%>%filter(pps.strand==1)%>%bind_rows(To.Rev.Comp)
# Assign the target and non-target strands based on whether each of the matches are on the same strand as the PPS then calculate the distance from the PPS to each hit.
Data<-Data%>%mutate(target.strand=ifelse(strand == pps.strand, "t", "n"))%>%mutate(dist.from.PPS=target.pos-pps.target.pos)
# Identify protospacers that are closer when the genome is treated as linear
Data<-Data%>%ungroup()%>%mutate(shorter.distance.exists = ifelse(abs(as.numeric(dist.from.PPS)) > as.numeric(genome.length)/2, T,F))
# Get genome distances from circular genomes
lengths.greater.than.half<-Data%>%filter(shorter.distance.exists == T)%>%
mutate(dist.from.PPS=ifelse(dist.from.PPS<0,as.numeric(dist.from.PPS)+as.numeric(genome.length),as.numeric(dist.from.PPS)-as.numeric(genome.length)))
##combine the two sets of genomes
Data<-Data%>%filter(shorter.distance.exists==F)%>%bind_rows(lengths.greater.than.half)%>%select(-pps.target.pos, -shorter.distance.exists)
# Separate and update the PPS data
PPS.dat<-Data%>%filter(spacer.order.number==1)%>%mutate(five.three.prime.dir = "0")
# Select the data that is not the PPS and calculate 5' and 3' direction
not.PPS.dat<-Data%>%filter(spacer.order.number != 1)
not.PPS.dat<-not.PPS.dat%>%mutate(five.three.prime.dir=ifelse(target.strand == "t", ifelse(dist.from.PPS < 0 , "5", "3"),
ifelse(dist.from.PPS < 0 , "3", "5")))
# Combine the data and check counts
Data<-PPS.dat%>%bind_rows(not.PPS.dat)
rm(targets.dat.replicated)
#Data<-Data%>%mutate(dist.from.PPS=ifelse(target.strand=="t",dist.from.PPS,dist.from.PPS*-1)) #@@ added to correct the nt strand mapping
Data<-Data%>%mutate(strand.plus.direction = paste(target.strand, five.three.prime.dir, sep = "_"))
return(Data)
}
protospacer_distributionB<-function(ExpData, RndData, Subtype.label,CI){ #Easier formatting for Prism and reports percentile
## Setup #####
xlim.num<-mapping.size
trials<-max(RndData$trial)
##select the random data for a given subtype
RndData<-RndData%>%filter(Subtype == Subtype.label & spacer.order.number > 1)
##label the data as random and include the group number
RndData<-RndData%>%mutate(data.type = paste("random",sprintf('%0.4d',trial),sep="_"))%>%
select(dist.from.PPS, data.type, target.strand)
# Select and label the observed experimental (bioinformatic) data
ExpData<-ExpData%>%filter(Subtype == Subtype.label & spacer.order.number > 1)
ExpData<-ExpData%>%mutate(data.type = "observed")%>%
select(dist.from.PPS, data.type, target.strand)
## Calculate densities #####
##combine the random and real data
D<-ExpData%>%bind_rows(RndData)
##select the strand
dens<-D%>%filter(target.strand=="t")%>%group_by(data.type) %>%
## calculate densities for each group over same range; store in list column
summarise(d = list(density(dist.from.PPS, from = -xlim.num, to = xlim.num, n = 2*xlim.num/binwidth, bw = smoothing.val)))
density.data = as.data.frame(do.call("cbind", lapply(dens$d, "[[", "y")))
colnames(density.data)<-as.character(c("obs_.t",paste("random_t",1:trials,sep="")))
nt<-as.data.frame(dens$d[[1]]$x)
colnames(nt)<-"bp"
Density.Table.t<-nt%>%bind_cols(density.data)
Density.Table.t<-Density.Table.t%>%mutate(Rnd..mean..t=apply(Density.Table.t[,3:(trials+2)],1,mean))%>%
mutate(Rnd.sd..t=apply(Density.Table.t[,3:(trials+2)],1,sd))%>%
mutate(Rnd.Q95max..t=apply(Density.Table.t[,3:(trials+2)],1,quantile,probs=CI))%>%
mutate(Rnd.Q95min..t=apply(Density.Table.t[,3:(trials+2)],1,quantile,probs=(1-CI)))
# Density.Table.t<-Density.Table.t%>%mutate(Rnd.CI..upper.t=Rnd..mean..t+1.96*Rnd.sd..t)
# Density.Table.t<-Density.Table.t%>%mutate(Rnd.CI.lower.t=Rnd..mean..t-1.96*Rnd.sd..t)
##select the strand
dens<-D%>%filter(target.strand=="n")%>%group_by(data.type) %>%
## calculate densities for each group over same range; store in list column
summarise(d = list(density(dist.from.PPS, from = -xlim.num, to = xlim.num, n = 2*xlim.num/binwidth, bw = smoothing.val)))
density.data = as.data.frame(do.call("cbind", lapply(dens$d, "[[", "y")))
colnames(density.data)<-as.character(c("obs_nt",paste("random_nt",1:trials,sep="")))
nt<-as.data.frame(dens$d[[1]]$x)
colnames(nt)<-"bp"
Density.Table.n<-nt%>%bind_cols(density.data*-1)
Density.Table.n<-Density.Table.n%>%mutate(Rnd..mean.nt=apply(Density.Table.n[,3:(trials+2)],1,mean))%>%
mutate(Rnd.sd.nt=apply(Density.Table.n[,3:(trials+2)],1,sd))%>%
mutate(Rnd.Q95max.nt=apply(Density.Table.n[,3:(trials+2)],1,quantile,probs=(1-CI)))%>%
mutate(Rnd.Q95min.nt=apply(Density.Table.n[,3:(trials+2)],1,quantile,probs=CI)) # Backwards for the nt strand.
# Density.Table.n<-Density.Table.n%>%mutate(Rnd.CI..upper.nt=Rnd..mean.nt-1.96*Rnd.sd.nt)
# Density.Table.n<-Density.Table.n%>%mutate(Rnd.CI.lower.nt=Rnd..mean.nt+1.96*Rnd.sd.nt)
Density.All<-Density.Table.n%>%left_join(Density.Table.t,by="bp")
Density.All<-Density.All%>%select(-contains("random"))
Density.All<-Density.All[,order(colnames(Density.All))]
return(Density.All)
} #takes the swipeData, random data and a subtype and generates a distribution table for plotting
normalise_distribution_valuesB<-function(dat){
max<-max(c(max(dat$obs_.t), min(dat$obs_nt)*-1))
norm.dat<-dat[,2:ncol(dat)]/as.numeric(max)
norm.dens<-dat%>%select(bp)%>%bind_cols(norm.dat)
return(norm.dens)
} ##normalises the prism format data so that the maximum density is 1.
cluster_analysis<-function(swipeData = swipeData, Subtype.label = "I-F"){
subtypeData = swipeData%>%filter(Subtype == Subtype.label)
loop.length = 1000
set.seed(100)
targets.dat.replicated<-subtypeData[rep(seq_len(nrow(subtypeData)), loop.length), ]
#targets.dat.replicated%>%targets.dat.replicated%>%filter(spacer.order_num > 1)
rh<-targets.dat.replicated%>%
mutate(dist.from.PPS = runif(min = -0.5, max = 0.5, n = nrow(targets.dat.replicated)))%>%
mutate(dist.from.PPS = round(dist.from.PPS*genome.length, 0))%>%
mutate(dist.from.PPS = ifelse(spacer.order.number == 1, 0, dist.from.PPS))%>%
mutate(target.strand = round(runif(min = 0, max = 1, n = nrow(targets.dat.replicated)), 0))%>%
mutate(target.strand = ifelse(target.strand == 1, "t", "n"))%>%
mutate(five.three.prime.dir = ifelse(dist.from.PPS < 0, ifelse(target.strand == "t", 5, 3), ifelse(target.strand == "t", 3, 5)))%>%
mutate(strand.plus.direction = paste(target.strand, five.three.prime.dir, sep = "_"))%>%
mutate(target.pos = runif(min = 0, max = 1, n = nrow(targets.dat.replicated)))%>%
mutate(target.pos = round(target.pos*genome.length, 0))
rm(targets.dat.replicated)
rh<-rh%>%group_by(host.target.pair, array.id, spacer.id, spacer.order.number)%>%mutate(replicate = row_number())%>%filter(spacer.order.number > 1)
dat<-subtypeData%>%filter(spacer.order.number > 1)
mean.distance<- rh%>%group_by(replicate)%>%summarise(mean.value = mean(abs(dist.from.PPS)))
sd.distance<- rh%>%group_by(replicate)%>%summarise(sd.value = sd(dist.from.PPS))
distanceSummaryRH<-left_join(mean.distance, sd.distance, by = "replicate")
mean.mean<-mean(distanceSummaryRH$mean.value)
sd.mean<-sd(distanceSummaryRH$mean.value)
mean.sd<-mean(distanceSummaryRH$sd.value)
sd.sd<-sd(distanceSummaryRH$sd.value)
n = length(dat$dist.from.PPS)
s = sd(dat$dist.from.PPS)        # sample standard deviation
SE = s/sqrt(n)
E = qt(.975, df=n-1)*SE
xbar = mean(abs(dat$dist.from.PPS))   # sample mean
ciData<-xbar + c(-E, E)
n = length(rh$dist.from.PPS)
s = sd(rh$dist.from.PPS)        # sample standard deviation
SE = s/sqrt(n)
E = qt(.975, df=n-1)*SE
xbar = mean(abs(rh$dist.from.PPS))   # sample mean
ciRandom<-xbar + c(-E, E)
return(paste(Subtype.label, pnorm(ciData[2], mean=mean.sd, sd=sd.sd, lower.tail=T), (mean(abs(rh$dist.from.PPS)) - mean(abs(dat$dist.from.PPS)))/mean(abs(rh$dist.from.PPS))*100 ))
} ##gives a p-value and clustering % for a subtype
ks_test_analysisB<-function(Exp.Data, Rnd.Data, Subtype.label){ # Doesn't take strand into consideration? is there another test we can use?
Rnd.Data<-Rnd.Data%>%filter(Subtype == Subtype.label & spacer.order.number > 1)
Exp.Data<-Exp.Data%>%filter(Subtype == Subtype.label & spacer.order.number > 1)
ks.res<-suppressWarnings(ks.test(Exp.Data$dist.from.PPS,Rnd.Data$dist.from.PPS))
return(ks.res)
} ##gives a p-value for the ks-test results
Data<-read.csv(paste(Out.Dir,"Data/PPS_Distances_Added.csv",sep=""),as.is=T)
swipeData.In<- read.table("Input/refseq_83_swipe_setup.txt", comment.char = "", fill = T, sep = "\t", header = T, quote = "", as.is = T)
dat <- read.csv("Output/Data/FinalData.csv")
View(dat)
hosts <- read.csv("Output/AllHostGenomes.csv")
View(hosts)
hosts <- hosts%>%select(host.target.pair, array.id, spacer.number, array.length)
hosts <- hosts%>%select(host.target.pair, array.id, spacer.number, array.length)%>%unique()
dat <- dat%>%left_join(hosts, by = c("host.target.pair", "array.id", "spacer.number"))
View(dat)
targetRange <- dat%>%group_by(host.acc.)%>%mutate(target.count = n())
View(targetRange)
dat <- read.csv("Output/Data/FinalData.csv")
targetRange <- dat%>%group_by(host.acc.)%>%mutate(target.count = n())
targetRange <- dat%>%group_by(host.acc.)%>%mutate(target.count = n())%>%mutate(hits.prop = hits.count/array.length)%>%mutate(mean.hits.prop = mean(hits.prop))%>%select(host.acc., target.count, mean.hits.prop)%>%unique()
ggplot(data = targetRange, aes(x = target.count, y = mean.hits.prop)) +
geom_point()
targetLM <- lm(target.count ~ mean.hits.prop, data = targetRange)
summary(targetLM)
knitr::opts_chunk$set(echo = TRUE)
#install.packages("EMT")
##load packages
library(EMT)
install.packages("EMT")
knitr::opts_chunk$set(echo = TRUE)
#install.packages("EMT")
##load packages
library(EMT)
library(tidyverse)
library(zoo)
setwd("~/Brown_Lab/R-script-and-files")
dir.create("Output",showWarnings = F)
dir.create("Output/Discard",showWarnings = F)
dir.create("Output/Data",showWarnings = F)
dir.create("Output/Analysis",showWarnings = F)
Out.Dir<-"Output/"
Run.Clean<-T
Objects.To.Keep<-c("Objects.To.Keep","Run.Clean","Counts","Out.Dir","quadrant_analysis","generate_random_distributionB","ks_test_analysisB","normalise_distribution_values","protospacer_distributionB")
quadrant_analysis<-function(dat, Subtype.label, use.all.hits){
dat<-dat%>%filter(Subtype == Subtype.label) # move this out of the function to allow type II systems to be pooled?
if(use.all.hits == T){
Data<-dat%>%filter(spacer.order.number >= 2)
}else if(use.all.hits == F){
Data<-dat%>%filter(spacer.order.number == 2 | spacer.order.number == 3)
#@@ testing         Data<-dat%>%filter(spacer.order.number == 2)
}
Data<-Data%>%mutate(tmp = paste(target.strand, five.three.prime.dir, sep = "_"))
quadrants<-as.data.frame(table(Data$tmp))
total<-sum(quadrants$Freq)
quadrants<-quadrants%>%mutate(percentage = round(Freq/total*100, 2))
strands<-as.data.frame(table(Data$target.strand))
strands<-strands%>%mutate(percentage = round(Freq/total*100, 2))
mat<-matrix(c(round(quadrants[4,2]), round(quadrants[3,2]),round(quadrants[1,2]), round(quadrants[2,2]) ), nrow = 2, byrow = T) #@@ Does this do anything?
quadrants<-quadrants%>%mutate(rowNum = c(3,4,1,2))%>%arrange(rowNum)%>%select(-rowNum)
#mat.res<-multinomial.test(observed = quadrants$Freq, prob = c(0.25, 0.25, 0.25, 0.25), MonteCarlo = T, ntrial = 10000000) @@ I don't think the Monte Carlo is necessary for our (simple) system - you need to run lots of trials for this to give a valid p value. On my laptop it is faster to run the mathematical version....
strands.prob<-binom.test(strands$Freq[2],total,p=0.5)
mat.res<-multinomial.test(observed = quadrants$Freq, prob = c(0.25, 0.25, 0.25, 0.25))
#Out.Table<-tbl_df("Host-Target pairs")%>%mutate(Freq=length(unique(Data$host.target.pair)))
Host.Target.Pairs<-nrow(Data%>%filter(spacer.order.number==1))
Out.Table<-tbl_df("Host-Target pairs")%>%mutate(Freq=Host.Target.Pairs)
Out.Table<-Out.Table%>%bind_rows(tbl_df("Hits not incl. PPS")%>%mutate(Freq=total))
Out.Table<-Out.Table%>%bind_rows(tbl_df("Quadrant p-value")%>%mutate(Freq=round(mat.res$p.value, 4)))
Out.Table<-Out.Table%>%bind_rows(tbl_df("Strand p-value")%>%mutate(Freq=round(strands.prob$p.value,4)))
Out.Table<-Out.Table%>%rename("Var1"=value)
Out.Table<-Out.Table%>%full_join(quadrants)%>%full_join(strands)
Out.Table[is.na(Out.Table)]<-0
print(paste("Subtype =",Subtype.label))
print(Out.Table)
#print(strands)
#print(quadrants)
return(Out.Table)
} ##Looks at the strand and quadrant distributions. It only needs swipeData and a subtype to run.
generate_random_distributionB<-function(swipeData,Size){ # Uses the same distance and strand calling as the main script including circular genome correction.
##generate the random dataset
set.seed(100)
# Trim the table
swipeData<-swipeData%>%select(host.target.pair,Subtype,array.id,target.acc.,unique.spacer.target.match,spacer.order.number,target.pos,strand,genome.length)
# Generate dataset with n (Size) replicates
targets.dat.replicated<-swipeData[rep(seq_len(nrow(swipeData)), Size), ]
targets.dat.replicated<-targets.dat.replicated%>%arrange(unique.spacer.target.match)%>%mutate(trial = rep(1:Size, nrow(swipeData)))%>%
mutate(host.target.pair=paste(host.target.pair,"_rep",trial,sep=""))
#length(targets.dat.replicated)-length(unique(targets.dat.replicated))
# Randomly assign protospacer sites and strands
Rnd.Data<-targets.dat.replicated%>%rowwise()%>%mutate(strand=sample(c(-1,1),1))%>%mutate(target.pos=sample(genome.length,1))
# Now perform the same strand and distance assignments as the main script
# Get the PPS data so that columns containing position and strand can be used to work out strand and direction for the subsequent matches
ppsData<-Rnd.Data%>%filter(spacer.order.number == 1)%>%
mutate(pps.strand = strand)%>%
mutate(pps.target.pos = target.pos)%>%
select(host.target.pair, pps.strand, pps.target.pos)
Data<-Rnd.Data%>%left_join(ppsData, by = "host.target.pair")%>%ungroup()
# Set the PPS to always be the top strand - if the PPS is on the bottom strand, reverse complement the target and change the position values
To.Rev.Comp<-Data%>%filter(pps.strand==-1)
# Flip the strand
To.Rev.Comp<-To.Rev.Comp%>%mutate(strand=strand*-1,pps.strand=pps.strand*-1,target.pos=(genome.length-target.pos),pps.target.pos=(genome.length-pps.target.pos))
# Rejoin the data
Data<-Data%>%filter(pps.strand==1)%>%bind_rows(To.Rev.Comp)
# Assign the target and non-target strands based on whether each of the matches are on the same strand as the PPS then calculate the distance from the PPS to each hit.
Data<-Data%>%mutate(target.strand=ifelse(strand == pps.strand, "t", "n"))%>%mutate(dist.from.PPS=target.pos-pps.target.pos)
# Identify protospacers that are closer when the genome is treated as linear
Data<-Data%>%ungroup()%>%mutate(shorter.distance.exists = ifelse(abs(as.numeric(dist.from.PPS)) > as.numeric(genome.length)/2, T,F))
# Get genome distances from circular genomes
lengths.greater.than.half<-Data%>%filter(shorter.distance.exists == T)%>%
mutate(dist.from.PPS=ifelse(dist.from.PPS<0,as.numeric(dist.from.PPS)+as.numeric(genome.length),as.numeric(dist.from.PPS)-as.numeric(genome.length)))
##combine the two sets of genomes
Data<-Data%>%filter(shorter.distance.exists==F)%>%bind_rows(lengths.greater.than.half)%>%select(-pps.target.pos, -shorter.distance.exists)
# Separate and update the PPS data
PPS.dat<-Data%>%filter(spacer.order.number==1)%>%mutate(five.three.prime.dir = "0")
# Select the data that is not the PPS and calculate 5' and 3' direction
not.PPS.dat<-Data%>%filter(spacer.order.number != 1)
not.PPS.dat<-not.PPS.dat%>%mutate(five.three.prime.dir=ifelse(target.strand == "t", ifelse(dist.from.PPS < 0 , "5", "3"),
ifelse(dist.from.PPS < 0 , "3", "5")))
# Combine the data and check counts
Data<-PPS.dat%>%bind_rows(not.PPS.dat)
rm(targets.dat.replicated)
#Data<-Data%>%mutate(dist.from.PPS=ifelse(target.strand=="t",dist.from.PPS,dist.from.PPS*-1)) #@@ added to correct the nt strand mapping
Data<-Data%>%mutate(strand.plus.direction = paste(target.strand, five.three.prime.dir, sep = "_"))
return(Data)
}
protospacer_distributionB<-function(ExpData, RndData, Subtype.label,CI){ #Easier formatting for Prism and reports percentile
## Setup #####
xlim.num<-mapping.size
trials<-max(RndData$trial)
##select the random data for a given subtype
RndData<-RndData%>%filter(Subtype == Subtype.label & spacer.order.number > 1)
##label the data as random and include the group number
RndData<-RndData%>%mutate(data.type = paste("random",sprintf('%0.4d',trial),sep="_"))%>%
select(dist.from.PPS, data.type, target.strand)
# Select and label the observed experimental (bioinformatic) data
ExpData<-ExpData%>%filter(Subtype == Subtype.label & spacer.order.number > 1)
ExpData<-ExpData%>%mutate(data.type = "observed")%>%
select(dist.from.PPS, data.type, target.strand)
## Calculate densities #####
##combine the random and real data
D<-ExpData%>%bind_rows(RndData)
##select the strand
dens<-D%>%filter(target.strand=="t")%>%group_by(data.type) %>%
## calculate densities for each group over same range; store in list column
summarise(d = list(density(dist.from.PPS, from = -xlim.num, to = xlim.num, n = 2*xlim.num/binwidth, bw = smoothing.val)))
density.data = as.data.frame(do.call("cbind", lapply(dens$d, "[[", "y")))
colnames(density.data)<-as.character(c("obs_.t",paste("random_t",1:trials,sep="")))
nt<-as.data.frame(dens$d[[1]]$x)
colnames(nt)<-"bp"
Density.Table.t<-nt%>%bind_cols(density.data)
Density.Table.t<-Density.Table.t%>%mutate(Rnd..mean..t=apply(Density.Table.t[,3:(trials+2)],1,mean))%>%
mutate(Rnd.sd..t=apply(Density.Table.t[,3:(trials+2)],1,sd))%>%
mutate(Rnd.Q95max..t=apply(Density.Table.t[,3:(trials+2)],1,quantile,probs=CI))%>%
mutate(Rnd.Q95min..t=apply(Density.Table.t[,3:(trials+2)],1,quantile,probs=(1-CI)))
# Density.Table.t<-Density.Table.t%>%mutate(Rnd.CI..upper.t=Rnd..mean..t+1.96*Rnd.sd..t)
# Density.Table.t<-Density.Table.t%>%mutate(Rnd.CI.lower.t=Rnd..mean..t-1.96*Rnd.sd..t)
##select the strand
dens<-D%>%filter(target.strand=="n")%>%group_by(data.type) %>%
## calculate densities for each group over same range; store in list column
summarise(d = list(density(dist.from.PPS, from = -xlim.num, to = xlim.num, n = 2*xlim.num/binwidth, bw = smoothing.val)))
density.data = as.data.frame(do.call("cbind", lapply(dens$d, "[[", "y")))
colnames(density.data)<-as.character(c("obs_nt",paste("random_nt",1:trials,sep="")))
nt<-as.data.frame(dens$d[[1]]$x)
colnames(nt)<-"bp"
Density.Table.n<-nt%>%bind_cols(density.data*-1)
Density.Table.n<-Density.Table.n%>%mutate(Rnd..mean.nt=apply(Density.Table.n[,3:(trials+2)],1,mean))%>%
mutate(Rnd.sd.nt=apply(Density.Table.n[,3:(trials+2)],1,sd))%>%
mutate(Rnd.Q95max.nt=apply(Density.Table.n[,3:(trials+2)],1,quantile,probs=(1-CI)))%>%
mutate(Rnd.Q95min.nt=apply(Density.Table.n[,3:(trials+2)],1,quantile,probs=CI)) # Backwards for the nt strand.
# Density.Table.n<-Density.Table.n%>%mutate(Rnd.CI..upper.nt=Rnd..mean.nt-1.96*Rnd.sd.nt)
# Density.Table.n<-Density.Table.n%>%mutate(Rnd.CI.lower.nt=Rnd..mean.nt+1.96*Rnd.sd.nt)
Density.All<-Density.Table.n%>%left_join(Density.Table.t,by="bp")
Density.All<-Density.All%>%select(-contains("random"))
Density.All<-Density.All[,order(colnames(Density.All))]
return(Density.All)
} #takes the swipeData, random data and a subtype and generates a distribution table for plotting
normalise_distribution_valuesB<-function(dat){
max<-max(c(max(dat$obs_.t), min(dat$obs_nt)*-1))
norm.dat<-dat[,2:ncol(dat)]/as.numeric(max)
norm.dens<-dat%>%select(bp)%>%bind_cols(norm.dat)
return(norm.dens)
} ##normalises the prism format data so that the maximum density is 1.
cluster_analysis<-function(swipeData = swipeData, Subtype.label = "I-F"){
subtypeData = swipeData%>%filter(Subtype == Subtype.label)
loop.length = 1000
set.seed(100)
targets.dat.replicated<-subtypeData[rep(seq_len(nrow(subtypeData)), loop.length), ]
#targets.dat.replicated%>%targets.dat.replicated%>%filter(spacer.order_num > 1)
rh<-targets.dat.replicated%>%
mutate(dist.from.PPS = runif(min = -0.5, max = 0.5, n = nrow(targets.dat.replicated)))%>%
mutate(dist.from.PPS = round(dist.from.PPS*genome.length, 0))%>%
mutate(dist.from.PPS = ifelse(spacer.order.number == 1, 0, dist.from.PPS))%>%
mutate(target.strand = round(runif(min = 0, max = 1, n = nrow(targets.dat.replicated)), 0))%>%
mutate(target.strand = ifelse(target.strand == 1, "t", "n"))%>%
mutate(five.three.prime.dir = ifelse(dist.from.PPS < 0, ifelse(target.strand == "t", 5, 3), ifelse(target.strand == "t", 3, 5)))%>%
mutate(strand.plus.direction = paste(target.strand, five.three.prime.dir, sep = "_"))%>%
mutate(target.pos = runif(min = 0, max = 1, n = nrow(targets.dat.replicated)))%>%
mutate(target.pos = round(target.pos*genome.length, 0))
rm(targets.dat.replicated)
rh<-rh%>%group_by(host.target.pair, array.id, spacer.id, spacer.order.number)%>%mutate(replicate = row_number())%>%filter(spacer.order.number > 1)
dat<-subtypeData%>%filter(spacer.order.number > 1)
mean.distance<- rh%>%group_by(replicate)%>%summarise(mean.value = mean(abs(dist.from.PPS)))
sd.distance<- rh%>%group_by(replicate)%>%summarise(sd.value = sd(dist.from.PPS))
distanceSummaryRH<-left_join(mean.distance, sd.distance, by = "replicate")
mean.mean<-mean(distanceSummaryRH$mean.value)
sd.mean<-sd(distanceSummaryRH$mean.value)
mean.sd<-mean(distanceSummaryRH$sd.value)
sd.sd<-sd(distanceSummaryRH$sd.value)
n = length(dat$dist.from.PPS)
s = sd(dat$dist.from.PPS)        # sample standard deviation
SE = s/sqrt(n)
E = qt(.975, df=n-1)*SE
xbar = mean(abs(dat$dist.from.PPS))   # sample mean
ciData<-xbar + c(-E, E)
n = length(rh$dist.from.PPS)
s = sd(rh$dist.from.PPS)        # sample standard deviation
SE = s/sqrt(n)
E = qt(.975, df=n-1)*SE
xbar = mean(abs(rh$dist.from.PPS))   # sample mean
ciRandom<-xbar + c(-E, E)
return(paste(Subtype.label, pnorm(ciData[2], mean=mean.sd, sd=sd.sd, lower.tail=T), (mean(abs(rh$dist.from.PPS)) - mean(abs(dat$dist.from.PPS)))/mean(abs(rh$dist.from.PPS))*100 ))
} ##gives a p-value and clustering % for a subtype
ks_test_analysisB<-function(Exp.Data, Rnd.Data, Subtype.label){ # Doesn't take strand into consideration? is there another test we can use?
Rnd.Data<-Rnd.Data%>%filter(Subtype == Subtype.label & spacer.order.number > 1)
Exp.Data<-Exp.Data%>%filter(Subtype == Subtype.label & spacer.order.number > 1)
ks.res<-suppressWarnings(ks.test(Exp.Data$dist.from.PPS,Rnd.Data$dist.from.PPS))
return(ks.res)
} ##gives a p-value for the ks-test results
if (exists("Counts")==F){
Counts<-tbl_df(matrix(c("I-A","I-B","I-C","I-D","I-E","I-F","II-A","II-C"),ncol=1,byrow=TRUE)) #Make a table to keep track of the data
colnames(Counts)<-c("subtype.list")
Out.Dir<-"Output/"
} #rm(Counts)
matrix(c("I-A","I-B","I-C","I-D","I-E","I-F","II-A","II-C"),ncol=1,byrow=TRUE)
Counts<-as.data.frame(matrix(c("I-A","I-B","I-C","I-D","I-E","I-F","II-A","II-C"),ncol=1,byrow=TRUE)) #Make a table to keep track of the data
if (exists("Counts")==F){
Counts<-as.data.frame(matrix(c("I-A","I-B","I-C","I-D","I-E","I-F","II-A","II-C"),ncol=1,byrow=TRUE)) #Make a table to keep track of the data
colnames(Counts)<-c("subtype.list")
Out.Dir<-"Output/"
} #rm(Counts)
swipeData.In<- read.table("Input/refseq_83_swipe_setup.txt", comment.char = "", fill = T, sep = "\t", header = T, quote = "", as.is = T)
Input
